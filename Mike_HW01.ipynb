{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeNsiah10/DLTFpT/blob/master/Mike_HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ighIhhiLaBtR"
      },
      "source": [
        "## Practical Exercise 1: word2vec\n",
        "By Joline Janz and Frederik Wollatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpTQUaW0co-k"
      },
      "source": [
        "Each Notebook will contribute equaly to your final grade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCmr1p64aBtW"
      },
      "source": [
        "This practical Exercise is presented as an IPython Notebook, with the code written for recent versions of **Python 3**. \n",
        "\n",
        "To execute a notebook cell, press `shift-enter`. The return value of the last command will be displayed, if it is not `None`.\n",
        "\n",
        "Potentially useful library documentation, references, and resources:\n",
        "\n",
        "* IPython notebooks: <https://ipython.org/ipython-doc/3/notebook/notebook.html#introduction>\n",
        "* Numpy numerical array library: <https://docs.scipy.org/doc/>\n",
        "* Gensim's word2vec: <https://radimrehurek.com/gensim/models/word2vec.html>\n",
        "* Bokeh interactive plots: <http://bokeh.pydata.org/en/latest/> (we provide plotting code here, but click the thumbnails for more examples to copy-paste)\n",
        "* scikit-learn ML library (aka `sklearn`): <http://scikit-learn.org/stable/documentation.html>\n",
        "* nltk NLP toolkit: <http://www.nltk.org/>\n",
        "* tutorial for processing xml in python using `lxml`: <http://lxml.de/tutorial.html> (we did this for you below, but in case you need it in the future)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzHhEXkWco-r"
      },
      "source": [
        "In this Notebook you will learn the basics on how to construct a word-embedding. As you recall from the lecture, word-embeddings are a type of word representation that allows words with similar meaning to have a similar representation. To do this, words are represented as real-valued vectors in a predefined vector space. Additionally, you will also learn how to use some basic NLP tools like tokenization and regular Expressions!\n",
        "Good Luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "569W6MImaBtX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNUMnrjICiSf",
        "outputId": "38371466-4122-49ea-d2f1-fbbe421c4487"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 36.3 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=89d4e266624c01394f5e30bb0de01f946a622bb8cb7c03ca0e408df1cca3605f\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words\n",
            "Successfully installed docopt-0.6.2 num2words-0.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rsgimgrUaBtd"
      },
      "outputs": [],
      "source": [
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from bokeh.io import output_notebook\n",
        "from num2words import num2words\n",
        "output_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ofHeuGejaZHs"
      },
      "outputs": [],
      "source": [
        "from sys import executable\n",
        "try: \n",
        "    import nltk\n",
        "except:\n",
        "    import sys #Here we install nltk. You only have to execute this cell once!\n",
        "    !{sys.executable} -m pip install nltk \n",
        "    import nltk\n",
        "    nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW9iCs7mGy0M",
        "outputId": "5ebbbb31-0eef-47b6-e174-d628c9cde0ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haav4K7YaBti"
      },
      "source": [
        "### Part 0: Load the TED dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_L2VA4Mco-2"
      },
      "source": [
        "As input we need a large amount of text data. We will use the TED database, which are the transcripts of Ted Talks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "stf464BBaBtj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import lxml.etree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2GPN2XwC-kwo",
        "outputId": "3abf3d90-1a36-4e0c-fdf7-193343efb93c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-408425b5-fcd3-471f-a97f-e26327a822bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-408425b5-fcd3-471f-a97f-e26327a822bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ted_en-20160408.zip to ted_en-20160408.zip\n"
          ]
        }
      ],
      "source": [
        "# Upload the dataset if it's not already there: this may take a minute as it is 75MB\n",
        "if not os.path.isfile('ted_en-20160408.zip'):\n",
        "  from google.colab import files\n",
        "  # select the file \"ted_en-20160408.zip\" from your local drive here\n",
        "  uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0oWf1JkvaBtr"
      },
      "outputs": [],
      "source": [
        "# For now, we're only interested in the subtitle text, so let's extract that from the XML:\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
        "del doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UVfpExaBtu"
      },
      "source": [
        "### Part 1: Preprocessing\n",
        "\n",
        "Before using our text, we need to preprocess it. Therefore, we bring it into a form that is predictable and analyzable. We attempt to clean up the raw subtitles a bit, so that we get only complete sentences. The following substring shows examples of what we're trying to get rid of. Since it's hard to define precisely what we want to get rid of, we'll just use some simple heuristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKWHxHG7bkWa"
      },
      "source": [
        "<h4>Execercise 1.1 (2 Points)</h4> \n",
        "Before we work with the data we should have a look at it. We already marked some areas for you, that need to be cleaned. You do not have to code anything here, you just have to become aware of sensitive preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGpx6RFzaBtv",
        "outputId": "e67ab0aa-1b44-4d23-c5cd-f80cc1c241fb",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? (Ball squeaks) Wow.\n",
            "Laura Schulz: Told you. (Laughs)\n",
            "\n",
            "You will earn 10% of any gold \n"
          ]
        }
      ],
      "source": [
        "#Have a look at the output of this code, to see some examples\n",
        "i = input_text.find(\"Hyowon Gweon: See this?\")\n",
        "print(input_text[i:i+145])\n",
        "\n",
        "\n",
        "i = input_text.find(\"You will earn\")\n",
        "print(input_text[i:i+30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y7gtjkWcJ-2"
      },
      "source": [
        "For example the parenthesized strings like \"(Ball squeaks)\" and symbols like % could have a negative impact on the word embeddings. Name at least two more problematic sections and how you would solve them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqC68N5Yco_E"
      },
      "source": [
        "<b>Your Solution:</b> \n",
        "<br>- Parenthesized Strings\n",
        "<br>- Percent-Symbol\n",
        "<br>- punctuation(question marks,colons etc)\n",
        "<br>- stopwords\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH2seZr2aBt1"
      },
      "source": [
        "<h4>Exercise 1.2 (2 Points)</h4>\n",
        "Let's start by removing all parenthesized strings using a regex:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u3YXkh5aBt1",
        "outputId": "0b74eb5f-b7a1-4d0a-b3b6-899e92731300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before\n",
            "Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? (\n",
            "after\n",
            "Hyowon Gweon: See this?  Did you see that?  Cool. See this one?  Wow.\n",
            "Laura Schulz: Told you.\n"
          ]
        }
      ],
      "source": [
        "i = input_text.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"before\")\n",
        "print(input_text[i:i+93])\n",
        "\n",
        "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text) #Identifies everything in parenthesis and replaces it with \"\"\n",
        "\n",
        "\n",
        "#you can use this to verify\n",
        "i = input_text_noparens.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"after\")\n",
        "print(input_text_noparens[i:i+93])\n",
        "\n",
        "#We won't worry about the irregular spaces since we'll later split the text into sentences and tokenize it anyway."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtwPNpChdjww"
      },
      "source": [
        "Try it yourself: Replace every percentage Symbol with the word \"percent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o6oEW0AdiDY",
        "outputId": "83e5e562-daf8-440f-da49-c0441bb292f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before\n",
            "You will earn 10% of any gold \n",
            "after\n",
            "You will earn 10 percent  of any gold\n"
          ]
        }
      ],
      "source": [
        "i = input_text_noparens.find(\"You will earn\")\n",
        "print(\"before\")\n",
        "print(input_text_noparens[i:i+30])\n",
        "\n",
        "#Your implementation goes here!\n",
        "input_text_clean=re.sub(r\"%\",\" percent \",input_text_noparens)\n",
        "\n",
        "i = input_text_clean.find(\"You will earn\")\n",
        "print(\"after\")\n",
        "print(input_text_clean[i:i+37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67ZOyc_9e2aS"
      },
      "source": [
        "<h4>Exercise 1.3 (4 Points)</h4>\n",
        "Now you have learned how to use RegEx to your advantage and have Identified potential parts of the text, that we want to eliminate. We have already implented how to remove all parenthesized strings. Now we want to replace every number in the text with its respectiv string. E.g. 10 -> ten ; \n",
        "42 -> forty-two\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6NKj6fNfXMQ",
        "outputId": "7a65246f-7850-47ae-a532-735572391515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before\n",
            "You will earn 10 percent  of any gold\n",
            "after\n",
            "You will earn ten percent  of any gol\n"
          ]
        }
      ],
      "source": [
        "i = input_text_clean.find(\"You will earn\") #find problematic parts\n",
        "print(\"before\")\n",
        "print(input_text_clean[i:i+37]) #and show them\n",
        "\n",
        "\n",
        "#Your implementation here\n",
        "input_text_clean=re.sub(r\"\\d+\",lambda x: num2words(int(x.group(0))),input_text_clean)\n",
        "\n",
        "\n",
        "i = input_text_clean.find(\"You will earn\") #validate your method\n",
        "print(\"after\")\n",
        "print(input_text_clean[i:i+37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJEtm8eOaBt9"
      },
      "source": [
        "<h4>Exercise 1.4 (4 Points)</h4>\n",
        "What does this block of code do? Identify one possible flaw. You dont have to code anything here!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFUCfLOkco_K",
        "outputId": "2ea71c8c-158d-4514-f692-dda3c1106af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before:\n",
            "let's see what the baby does.\n",
            " Hyowon Gweon: See this?  Did you see that?  Cool. See this one?  Wow.\n",
            "Laura Schulz: Told you\n",
            "after:\n",
            " let's see what the baby does. See this?  Did you see that?  Cool. See this one?  Wow.\n"
          ]
        }
      ],
      "source": [
        "i = input_text_clean.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"before:\")\n",
        "print(input_text_clean[i-31:i+92])\n",
        "\n",
        "X = []\n",
        "for line in input_text_clean.split('\\n'):\n",
        "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
        "    X.extend(m.groupdict()['postcolon'])\n",
        "input_text_clean2=\"\".join(X)\n",
        "\n",
        "\n",
        "i = input_text_clean2.find(\"See this?\")\n",
        "print(\"after:\")\n",
        "print(input_text_clean2[i-31:i+55])"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ix75Rnrrco_M"
      },
      "source": [
        "Your Answer goes here!\n",
        "\n",
        "the code returns a dictionary of one or more of the subgroups pattern which matches the regular expression (only at the begining of a particular string within a sentence)\n",
        "\n",
        "FLAW: \n",
        "- all the characters specified of the subgroups will be neglected because the re.match searches only at the beginning of specified pattern.\n",
        "reason why we still see these characters when the text is printed out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX5lFA4XijPm"
      },
      "source": [
        "<h4>Exercise 1.5 (6 Points)</h4>\n",
        "\n",
        "To build our embedding we need to tokenize every single word. Therefore we first need to split the text into sentences and after that into words. \n",
        "Try it yourself or use the NLTK-Tools build for this (https://www.kite.com/python/docs/nltk.word_tokenize + https://www.kite.com/python/docs/nltk.sent_tokenize).\n",
        "To make it easier to build our Embedding we should also delete every character that is not a letter. Additionally, we could lower vocabulary count. A way to do this is by converting capital characters to lower case characters.\n",
        "\n",
        "Split your text into sentences and save them in the array `sentences_strings_ted`.\n",
        "Save one variabale `tokens` with all the tokens in the text and one array named `sentences_ted` that contains an array for every sentence, with all the tokenized words of that sentence.<br><br>\n",
        "Example:<br>\n",
        "If the Text looks like this: \"I love cake. You have to be honest, you love it too!\", the variables look like:<br><br>\n",
        "sentences_strings_ted=['I love cake.', 'You have to be honest, you love it too!']<br>\n",
        "sentences_ted=[['i', 'love', 'cake'], ['you', 'have', 'to', 'be', 'honest', 'you', 'love', 'it', 'too']]<br>\n",
        "tokens=['i', 'love', 'cake', 'you', 'have', 'to', 'be', 'honest', 'you', 'love', 'it', 'too']<br>\n",
        "\n",
        "\n",
        "Apply this to `input_text_clean`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_text_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH_E0b2uW8FW",
        "outputId": "14813029-f546-4a1c-d7a8-3d1a153c079f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24347900"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "OAvTSzWzYZfU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentences_strings_ted=sent_tokenize(input_text_clean[:24347900])\n",
        "#print(sentences_strings_ted)\n",
        "#splits text into strings of sentences\n",
        "\n",
        "sentences_ted=[]\n",
        "tokenizer=nltk.RegexpTokenizer(r\"\\w+\")\n",
        "for each_sentence in sentences_strings_ted:\n",
        "    lower=each_sentence.lower() #convert each_sentence to lower case\n",
        "    tokenize_sentence= tokenizer.tokenize(lower) # remove all punctuations\n",
        "    sentences_ted.append(tokenize_sentence)# create an array of sentences by appending the empty list to the tokenize sentence\n",
        "#print(sentences_ted)\n",
        "#prints a array of tokenized sentences without punctuation\n",
        "\n",
        "tokens=[]\n",
        "for x in sentences_ted:\n",
        "  for each_token in x:\n",
        "    tokens.append(each_token) # creates a list of each_token\n",
        "\n",
        "#print(tokens)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xX5uUMPnOF_F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUiFC0I5j31i"
      },
      "source": [
        "<h4>Exercise 1.6 (1 Point)</h4>\n",
        "The good side is, that by converting all capital letters is, we reduce the volume of the vocabulary. Thereby we dont differentiate between the the words \"today\" and \"Today\". \n",
        "Can you think of any downside to this process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yt08f-sco_O"
      },
      "source": [
        "YOUR ANSWER GOES HERE\n",
        "\n",
        "One of the downside is when we are building an nlp application to predict sentences. Capital letters will be crucial in such cases and converting letters to lower case may lead to wrong predictions been made. Also it  may change the word meaning or it's part of speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Fs3pzZmHHv"
      },
      "source": [
        "Now we can have a look at the processed dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooe1gfSZaBuG",
        "outputId": "9ea20c1e-11ee-469f-ed0e-77ece03cd186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "273384"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(sentences_ted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Jwdw8QxbaBuJ",
        "outputId": "272557bb-2141-42b0-fdcb-20fd925c6cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['ciao', 'bellos']\n"
          ]
        }
      ],
      "source": [
        "print(sentences_ted[0])\n",
        "print(sentences_ted[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjkAGHjaBuN"
      },
      "source": [
        "### Part 2: Word Frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLMH0iXaBuO"
      },
      "source": [
        "<h4>Exercise 2.1 (4 Points)</h4>\n",
        "Your next task will be to store the counts of the top 1000 most frequent words in a list called `counts_ted_top1000` ! There are multiple ways to do this. You can have a look at the Counter-Function(https://docs.python.org/2/library/collections.html) or the FreqDist-Function (https://www.kite.com/python/docs/nltk.FreqDist). If you dont trust any of those you can of course build your own function.\n",
        "In the end we want an array with tupels of the structure [(WordA,FrequencyA),(WordB,FrequencyB)]."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yg7VbYJl51PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "wUpgiAW4zmFn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LcQzY8iWaBuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c41f7d-6f80-4ac7-8267-72dfa337e01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 207804), ('and', 155217), ('to', 125184), ('of', 114824), ('a', 105406), ('that', 95149), ('i', 83206), ('in', 78072), ('it', 74749), ('you', 70940), ('we', 67638), ('is', 63292), ('s', 57127), ('this', 49269), ('so', 37069), ('they', 33102), ('was', 30808), ('for', 29714), ('are', 27996), ('have', 27349), ('but', 26744), ('what', 26523), ('on', 25962), ('with', 24706), ('one', 23659), ('can', 23382), ('t', 22765), ('about', 21249), ('there', 21044), ('be', 20201), ('as', 19492), ('at', 19234), ('all', 19032), ('not', 18627), ('do', 17930), ('my', 17929), ('re', 17013), ('people', 16723), ('like', 16277), ('if', 15869), ('from', 15454), ('now', 14394), ('our', 14061), ('he', 13993), ('an', 13918), ('just', 13899), ('these', 13882), ('or', 13863), ('when', 13279), ('because', 12879), ('very', 12364), ('me', 12301), ('out', 12163), ('by', 11937), ('them', 11595), ('how', 11578), ('know', 11508), ('up', 11447), ('going', 11366), ('had', 10904), ('more', 10903), ('think', 10465), ('who', 10446), ('were', 10180), ('see', 10180), ('two', 10163), ('your', 10093), ('their', 10029), ('which', 10021), ('would', 9911), ('here', 9897), ('really', 9676), ('get', 9377), ('ve', 9310), ('then', 9244), ('m', 9141), ('world', 8906), ('us', 8841), ('time', 8824), ('some', 8630), ('has', 8262), ('don', 8258), ('actually', 8011), ('into', 7859), ('hundred', 7792), ('way', 7736), ('where', 7724), ('will', 7618), ('years', 7538), ('things', 7537), ('other', 7285), ('no', 7230), ('could', 7184), ('go', 7170), ('well', 7142), ('want', 7119), ('been', 6937), ('make', 6806), ('right', 6523), ('she', 6425), ('said', 6361), ('something', 6307), ('those', 6292), ('first', 6238), ('than', 5972), ('much', 5907), ('also', 5696), ('look', 5686), ('new', 5572), ('thing', 5563), ('little', 5502), ('got', 5457), ('three', 5425), ('back', 5380), ('over', 5375), ('most', 5312), ('say', 5281), ('even', 5220), ('his', 5197), ('life', 5176), ('only', 5154), ('work', 5133), ('many', 4935), ('take', 4929), ('need', 4919), ('thousand', 4764), ('five', 4664), ('did', 4662), ('lot', 4546), ('kind', 4544), ('why', 4511), ('good', 4490), ('around', 4454), ('every', 4399), ('different', 4299), ('down', 4143), ('ll', 4137), ('let', 4135), ('her', 4120), ('through', 4079), ('same', 4037), ('being', 3971), ('come', 3968), ('day', 3800), ('d', 3796), ('year', 3791), ('use', 3786), ('nine', 3721), ('doing', 3707), ('four', 3646), ('put', 3613), ('twenty', 3612), ('called', 3494), ('any', 3449), ('percent', 3374), ('today', 3364), ('made', 3301), ('after', 3245), ('zero', 3244), ('thank', 3220), ('tell', 3201), ('great', 3188), ('human', 3172), ('find', 3080), ('fact', 3032), ('didn', 3032), ('talk', 3000), ('change', 2983), ('another', 2922), ('started', 2916), ('idea', 2901), ('big', 2874), ('last', 2873), ('own', 2861), ('before', 2856), ('its', 2846), ('should', 2779), ('never', 2779), ('better', 2775), ('give', 2758), ('thought', 2751), ('went', 2728), ('might', 2702), ('important', 2674), ('again', 2636), ('together', 2620), ('able', 2616), ('still', 2613), ('problem', 2606), ('off', 2586), ('next', 2583), ('part', 2564), ('course', 2561), ('system', 2533), ('him', 2514), ('does', 2513), ('ten', 2511), ('each', 2506), ('start', 2495), ('show', 2478), ('story', 2460), ('long', 2460), ('ago', 2457), ('came', 2451), ('brain', 2412), ('six', 2406), ('few', 2374), ('bit', 2343), ('between', 2340), ('used', 2332), ('place', 2327), ('technology', 2306), ('women', 2291), ('too', 2268), ('old', 2267), ('data', 2247), ('mean', 2245), ('water', 2240), ('looking', 2225), ('question', 2225), ('maybe', 2195), ('found', 2194), ('love', 2192), ('fifty', 2165), ('doesn', 2162), ('example', 2161), ('end', 2158), ('done', 2119), ('point', 2117), ('real', 2077), ('wanted', 2073), ('eight', 2067), ('ever', 2065), ('school', 2045), ('understand', 2045), ('thirty', 2042), ('sort', 2033), ('live', 2016), ('call', 2015), ('children', 2005), ('whole', 2002), ('always', 2001), ('seven', 1992), ('trying', 1979), ('may', 1977), ('person', 1961), ('away', 1950), ('believe', 1942), ('feel', 1941), ('try', 1938), ('million', 1933), ('working', 1929), ('help', 1924), ('everything', 1920), ('country', 1877), ('second', 1856), ('thinking', 1841), ('using', 1834), ('information', 1833), ('number', 1798), ('money', 1781), ('means', 1772), ('power', 1766), ('took', 1765), ('times', 1762), ('high', 1755), ('man', 1754), ('space', 1748), ('kids', 1740), ('home', 1729), ('become', 1720), ('create', 1716), ('small', 1708), ('design', 1681), ('making', 1678), ('best', 1655), ('left', 1653), ('getting', 1650), ('future', 1637), ('enough', 1636), ('quite', 1625), ('city', 1618), ('without', 1615), ('sense', 1600), ('happened', 1592), ('comes', 1585), ('social', 1584), ('probably', 1582), ('less', 1576), ('light', 1576), ('talking', 1575), ('am', 1575), ('energy', 1575), ('building', 1548), ('science', 1544), ('food', 1537), ('body', 1527), ('told', 1522), ('ask', 1519), ('interesting', 1519), ('half', 1510), ('pretty', 1492), ('hard', 1482), ('play', 1482), ('forty', 1481), ('anything', 1479), ('lives', 1478), ('countries', 1469), ('coming', 1466), ('such', 1466), ('family', 1463), ('stuff', 1444), ('dollars', 1433), ('earth', 1423), ('moment', 1423), ('imagine', 1420), ('across', 1417), ('side', 1409), ('saw', 1401), ('while', 1400), ('okay', 1394), ('happen', 1393), ('once', 1390), ('build', 1389), ('having', 1387), ('men', 1386), ('later', 1383), ('experience', 1379), ('asked', 1375), ('makes', 1374), ('living', 1373), ('seen', 1358), ('says', 1358), ('room', 1353), ('hand', 1352), ('simple', 1351), ('health', 1349), ('ways', 1348), ('else', 1346), ('case', 1345), ('ninety', 1343), ('yet', 1334), ('almost', 1334), ('days', 1329), ('young', 1329), ('nothing', 1322), ('bad', 1313), ('care', 1309), ('happens', 1309), ('goes', 1303), ('computer', 1301), ('move', 1300), ('states', 1296), ('reason', 1293), ('open', 1285), ('learn', 1284), ('africa', 1284), ('process', 1282), ('inside', 1277), ('someone', 1270), ('far', 1268), ('mind', 1267), ('project', 1267), ('remember', 1265), ('single', 1264), ('picture', 1258), ('both', 1255), ('whether', 1249), ('problems', 1246), ('saying', 1238), ('community', 1238), ('basically', 1238), ('already', 1235), ('within', 1234), ('looked', 1214), ('myself', 1212), ('billion', 1201), ('often', 1198), ('possible', 1198), ('business', 1197), ('planet', 1191), ('top', 1191), ('global', 1190), ('everybody', 1189), ('sure', 1188), ('public', 1188), ('set', 1185), ('wrong', 1179), ('child', 1178), ('car', 1176), ('book', 1176), ('keep', 1172), ('answer', 1172), ('yes', 1171), ('oh', 1166), ('hope', 1162), ('true', 1162), ('sometimes', 1162), ('history', 1161), ('guy', 1156), ('war', 1154), ('instead', 1149), ('months', 1147), ('ideas', 1146), ('sixty', 1145), ('looks', 1144), ('matter', 1140), ('eighty', 1137), ('government', 1133), ('amazing', 1132), ('united', 1131), ('since', 1121), ('age', 1120), ('bring', 1119), ('cells', 1119), ('job', 1112), ('heard', 1109), ('until', 1108), ('face', 1108), ('woman', 1106), ('wasn', 1102), ('read', 1096), ('control', 1094), ('isn', 1092), ('research', 1089), ('words', 1084), ('u', 1082), ('group', 1081), ('under', 1078), ('video', 1076), ('self', 1071), ('somebody', 1067), ('built', 1064), ('state', 1063), ('turn', 1052), ('friends', 1051), ('beautiful', 1051), ('line', 1048), ('knew', 1047), ('couple', 1046), ('order', 1042), ('form', 1041), ('yeah', 1039), ('internet', 1038), ('middle', 1037), ('music', 1036), ('piece', 1034), ('nature', 1030), ('head', 1030), ('though', 1028), ('seventy', 1026), ('stop', 1025), ('everyone', 1017), ('places', 1013), ('learned', 1011), ('language', 1011), ('run', 1010), ('night', 1008), ('decided', 1007), ('study', 1004), ('word', 1004), ('cancer', 1003), ('taking', 1000), ('works', 1000), ('became', 999), ('exactly', 998), ('species', 996), ('society', 995), ('completely', 995), ('education', 993), ('against', 990), ('stories', 987), ('large', 985), ('share', 984), ('level', 983), ('heart', 982), ('america', 981), ('model', 977), ('mother', 975), ('questions', 973), ('gets', 973), ('god', 967), ('company', 966), ('turns', 961), ('ourselves', 959), ('happening', 959), ('hear', 957), ('art', 957), ('themselves', 956), ('must', 952), ('itself', 950), ('rather', 942), ('students', 942), ('kinds', 941), ('name', 940), ('hours', 937), ('disease', 936), ('front', 933), ('house', 927), ('huge', 924), ('couldn', 924), ('created', 922), ('ok', 920), ('universe', 919), ('fifteen', 918), ('animals', 911), ('american', 908), ('environment', 907), ('worked', 906), ('ones', 905), ('minutes', 904), ('third', 903), ('black', 901), ('perhaps', 899), ('thousands', 898), ('past', 895), ('along', 886), ('finally', 885), ('others', 884), ('sound', 883), ('early', 883), ('game', 881), ('century', 878), ('based', 874), ('least', 874), ('ted', 873), ('per', 873), ('lots', 870), ('news', 866), ('figure', 865), ('free', 865), ('guys', 860), ('particular', 860), ('happy', 859), ('learning', 855), ('entire', 853), ('won', 852), ('gave', 850), ('machine', 849), ('india', 849), ('during', 845), ('systems', 844), ('air', 840), ('outside', 835), ('difference', 835), ('natural', 831), ('taken', 831), ('given', 824), ('changed', 824), ('leave', 820), ('cell', 819), ('close', 813), ('full', 812), ('behind', 810), ('cities', 810), ('scale', 804), ('difficult', 803), ('china', 803), ('takes', 795), ('companies', 794), ('yourself', 793), ('area', 793), ('reality', 791), ('seeing', 789), ('easy', 783), ('turned', 782), ('cost', 780), ('eyes', 777), ('moving', 770), ('team', 769), ('population', 765), ('culture', 764), ('york', 762), ('hands', 760), ('whatever', 758), ('began', 758), ('needs', 755), ('terms', 755), ('simply', 753), ('image', 753), ('needed', 752), ('father', 751), ('beginning', 750), ('local', 748), ('realized', 747), ('media', 746), ('death', 745), ('parents', 745), ('view', 742), ('walk', 742), ('white', 741), ('market', 739), ('parts', 738), ('ocean', 737), ('economic', 735), ('powerful', 733), ('known', 732), ('week', 732), ('size', 730), ('felt', 729), ('phone', 726), ('humans', 725), ('certain', 723), ('spend', 722), ('longer', 721), ('audience', 718), ('wonderful', 714), ('cannot', 712), ('grow', 711), ('common', 711), ('center', 709), ('tried', 708), ('fish', 705), ('land', 703), ('oil', 701), ('twelve', 699), ('political', 699), ('interested', 698), ('deal', 698), ('red', 697), ('gone', 696), ('amount', 694), ('hundreds', 693), ('weeks', 691), ('spent', 688), ('quickly', 688), ('opportunity', 688), ('step', 688), ('paper', 687), ('lost', 687), ('national', 686), ('blue', 685), ('green', 683), ('poor', 682), ('buy', 678), ('growth', 677), ('wouldn', 677), ('either', 676), ('patients', 673), ('sitting', 670), ('girl', 669), ('ability', 667), ('changes', 665), ('write', 664), ('challenge', 663), ('south', 663), ('low', 662), ('growing', 660), ('friend', 660), ('field', 659), ('shows', 657), ('born', 654), ('rest', 654), ('climate', 652), ('test', 645), ('street', 642), ('surface', 641), ('incredible', 641), ('average', 638), ('voice', 638), ('scientists', 638), ('value', 638), ('physical', 637), ('morning', 637), ('program', 637), ('pay', 637), ('feeling', 635), ('met', 635), ('behavior', 635), ('economy', 634), ('dna', 633), ('complex', 629), ('access', 628), ('risk', 627), ('animal', 626), ('structure', 625), ('feet', 623), ('attention', 622), ('ca', 621), ('areas', 620), ('anyone', 620), ('deep', 618), ('watch', 617), ('short', 615), ('absolutely', 614), ('speak', 613), ('brought', 613), ('die', 611), ('bottom', 611), ('numbers', 609), ('stage', 607), ('images', 607), ('realize', 606), ('law', 605), ('wrote', 605), ('understanding', 603), ('knowledge', 602), ('literally', 602), ('books', 602), ('movement', 601), ('ground', 600), ('giving', 599), ('eat', 598), ('alone', 596), ('force', 596), ('seems', 595), ('forward', 593), ('telling', 593), ('starting', 592), ('hold', 592), ('nice', 591), ('eleven', 590), ('sea', 590), ('developed', 589), ('kid', 586), ('individual', 585), ('millions', 584), ('support', 583), ('miles', 579), ('tools', 579), ('running', 579), ('online', 578), ('result', 577), ('act', 575), ('medical', 573), ('technologies', 573), ('north', 573), ('lab', 572), ('development', 571), ('blood', 570), ('fear', 569), ('nobody', 568), ('map', 568), ('issue', 565), ('personal', 565), ('key', 563), ('material', 562), ('recently', 561), ('theory', 559), ('patient', 559), ('cut', 558), ('fast', 557), ('cars', 556), ('sun', 555), ('changing', 554), ('playing', 552), ('clear', 552), ('especially', 551), ('girls', 551), ('soon', 550), ('choice', 546), ('fly', 546), ('creating', 542), ('normal', 541), ('discovered', 541), ('europe', 541), ('talked', 541), ('relationship', 541), ('gives', 540), ('generation', 539), ('dark', 534), ('type', 533), ('showed', 533), ('chance', 532), ('seem', 532), ('industry', 532), ('asking', 532), ('rate', 531), ('hour', 531), ('fun', 530), ('issues', 530), ('color', 530), ('designed', 530), ('university', 529), ('innovation', 529), ('several', 529), ('computers', 529), ('english', 529), ('tiny', 528), ('allow', 527), ('save', 527), ('digital', 527), ('focus', 527), ('class', 526), ('solve', 526), ('developing', 526), ('special', 525), ('network', 525), ('film', 525), ('solution', 522), ('wall', 522), ('baby', 522), ('situation', 521), ('reasons', 518), ('box', 518), ('knows', 518), ('meet', 517), ('dead', 517), ('stand', 517), ('term', 516), ('begin', 516), ('haven', 516), ('impact', 516), ('anybody', 516), ('beyond', 514), ('pictures', 514), ('please', 512), ('ice', 511), ('shape', 511), ('produce', 511), ('non', 509), ('cool', 506), ('resources', 505), ('robot', 505), ('groups', 504), ('likely', 504), ('stay', 504), ('rights', 504), ('available', 503), ('truth', 503), ('major', 503), ('cause', 502), ('evidence', 502), ('obviously', 502), ('writing', 502), ('experiment', 502), ('becomes', 501), ('modern', 501), ('drug', 501), ('incredibly', 500), ('aren', 498), ('bigger', 498), ('guess', 498), ('google', 497), ('product', 496), ('drugs', 496), ('lived', 495), ('involved', 493), ('perfect', 492), ('month', 492), ('effect', 490), ('similar', 490), ('putting', 490), ('office', 489), ('eye', 489), ('pick', 489), ('message', 488), ('violence', 486), ('quality', 485), ('web', 485), ('evolution', 483), ('security', 483), ('basic', 482), ('solar', 482), ('indeed', 482), ('boy', 482), ('general', 482), ('towards', 481), ('present', 480), ('drive', 480), ('send', 479), ('listen', 479), ('worth', 479), ('explain', 478), ('revolution', 478), ('certainly', 476), ('died', 476), ('ready', 475), ('teach', 475), ('journey', 474), ('hit', 473), ('walking', 473), ('approach', 472), ('led', 472), ('international', 471), ('scientific', 469), ('games', 469), ('potential', 468), ('crazy', 468), ('communities', 468), ('chinese', 468), ('device', 467), ('source', 465), ('camera', 465), ('rules', 464), ('sex', 464), ('carbon', 464), ('sounds', 463), ('reach', 460), ('starts', 460), ('examples', 459), ('west', 458), ('success', 455), ('measure', 455), ('particularly', 455), ('software', 455), ('totally', 454), ('suddenly', 453), ('action', 452), ('college', 451), ('higher', 451), ('code', 450), ('eventually', 449), ('sit', 445), ('democracy', 445), ('among', 444), ('minute', 444), ('largest', 442), ('showing', 441), ('hospital', 441), ('notice', 440), ('period', 440), ('mass', 439), ('develop', 439), ('dream', 438), ('onto', 438), ('plants', 437), ('favorite', 437), ('break', 437), ('add', 437), ('memory', 437), ('everywhere', 436), ('speed', 435), ('schools', 435), ('moved', 435), ('response', 435), ('wants', 434), ('extremely', 433), ('movie', 433), ('anyway', 433), ('individuals', 433), ('table', 433), ('wait', 433), ('medicine', 432), ('follow', 432), ('eighteen', 432), ('trust', 432), ('plant', 431), ('biggest', 431), ('watching', 430), ('organization', 430), ('creative', 429), ('road', 429), ('choose', 428), ('worse', 428), ('results', 428), ('lead', 427), ('doctor', 427), ('exciting', 426), ('grew', 425), ('jobs', 425), ('materials', 425), ('student', 424), ('east', 423), ('poverty', 423), ('positive', 423), ('safe', 422), ('plan', 422), ('strong', 422), ('fall', 422), ('essentially', 421), ('son', 420), ('object', 420), ('door', 420), ('vision', 419), ('further', 419), ('happiness', 419), ('continue', 419), ('including', 417), ('named', 417), ('role', 417), ('objects', 417), ('extraordinary', 416), ('standing', 415), ('skin', 415), ('leaders', 414), ('usually', 414), ('african', 414), ('conversation', 414), ('projects', 414), ('allowed', 412), ('models', 412), ('supposed', 411), ('faster', 410), ('interest', 410), ('families', 409), ('police', 409), ('fight', 409), ('tree', 407), ('connected', 407), ('screen', 406), ('cases', 406), ('finding', 405), ('goal', 405), ('somewhere', 405), ('buildings', 404), ('shown', 404), ('older', 403), ('teachers', 403), ('meaning', 403)]\n"
          ]
        }
      ],
      "source": [
        "#Your Code here\n",
        "counts_ted_top1000tupels=Counter(tokens).most_common(1000)\n",
        "print(counts_ted_top1000tupels)\n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a1sC288W8tin"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hti5NFdGaBuX"
      },
      "source": [
        "The following code is going to plot a histogramm of the distribution of the  top-30 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kjdE_DKLco_S",
        "outputId": "801daafb-b42e-4e98-8bc4-520f1c294eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "mostfreqn=30 #Here we define how many of them we want to see in the diagramm \n",
        "frequency=[y for (x,y) in counts_ted_top1000tupels][:mostfreqn]\n",
        "word=[x for (x,y) in counts_ted_top1000tupels][:mostfreqn]\n",
        "indices = np.arange(len(counts_ted_top1000tupels[:mostfreqn]))\n",
        "plt.bar(indices, frequency, color='r')\n",
        "plt.xticks(indices, word, rotation='vertical')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vnAj55Aco_U"
      },
      "source": [
        "You can clearly see, that many of the most common words are so called stop words. Stop Words are words, that are tipically not usefull to identify what a text is about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oRdD3e4aBud"
      },
      "source": [
        "### Part 3: Train Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp0JGmKWhrNd"
      },
      "source": [
        "Now it is time to train the modell. Gensim has an already implemented model that you can use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTA9yWtdhb6z"
      },
      "source": [
        "Using the provided modell is enough for the purposes of our notebook. If you want to dive deeper into the topic this youtube video https://www.youtube.com/watch?v=kKDYtZfriI8 could be a great guidance for you to get started. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "A_t4-aiTaBue"
      },
      "outputs": [],
      "source": [
        "#This takes a moment...dont worry :D\n",
        "from gensim.models import Word2Vec\n",
        "model_ted = Word2Vec(sentences_ted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKYd7ZemaBuj"
      },
      "source": [
        "### Part 4: Ted Learnt Representations (3 Points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7VvU82AaBuj"
      },
      "source": [
        "Finding similar words: (see gensim docs for functions, that might help you https://radimrehurek.com/gensim/models/keyedvectors.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW2Gbn4Qco_a"
      },
      "source": [
        "Now lets explore what we can do with this! How does \"house\" look in our embedding?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PKtCfFD4co_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035fab9b-a091-4d3a-c7fc-d83da21999da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.118172  , -1.8038176 ,  0.2873413 ,  0.70340294,  1.0511565 ,\n",
              "        0.35452986,  0.07264542, -0.24295959, -2.0454173 ,  0.9155764 ,\n",
              "        0.03813142, -0.17620935,  0.05188726, -1.9012448 ,  1.6864967 ,\n",
              "       -1.4055401 ,  0.28824097,  0.5900158 , -0.00493493,  0.5878428 ,\n",
              "       -0.9634781 ,  1.7425736 ,  0.29058185,  1.1317972 , -0.5981723 ,\n",
              "        0.92355895, -0.7555482 , -2.0217366 , -0.978458  , -0.9200602 ,\n",
              "        0.7150854 ,  1.3967779 ,  0.4016898 ,  1.1717817 ,  0.36559746,\n",
              "       -1.7513651 ,  1.3434836 ,  1.3051132 , -0.71211815,  0.2043968 ,\n",
              "        0.91094947, -1.6617523 , -0.6444162 , -1.1311524 , -1.0958731 ,\n",
              "        1.3943006 ,  0.69166434, -1.3939501 , -0.62782466, -0.17054433,\n",
              "       -0.70141405, -0.13597889, -1.6299165 , -0.7559026 , -2.465268  ,\n",
              "       -1.5412782 , -0.7334189 ,  0.24543999,  0.9424347 , -1.0303715 ,\n",
              "        0.2090416 , -1.4386944 ,  0.16990097, -0.55891186, -1.3887215 ,\n",
              "        1.0405275 ,  0.6022628 ,  1.1760272 , -0.47878027,  0.33909827,\n",
              "        0.85202414,  0.30848885, -0.6767984 , -0.3557693 ,  0.34991878,\n",
              "        0.8483398 ,  1.4450017 ,  0.4522795 ,  1.3814685 ,  0.15931474,\n",
              "       -0.61620283,  1.3066329 ,  0.10526445,  0.5394919 ,  0.43364102,\n",
              "        0.8287    , -0.46193096,  0.17104672, -0.3004245 , -0.7038203 ,\n",
              "       -0.34966525,  0.88390905,  0.5417206 , -1.5371397 , -0.7547967 ,\n",
              "       -0.922824  , -1.4857125 ,  0.31529278, -0.5253886 ,  0.0587308 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "#YOUR CODE\n",
        "model_ted.wv[\"house\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTZrG4pXco_b"
      },
      "source": [
        "What is the most similar word for \"town\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Y7Rr8Hktco_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414502f0-de54-4935-bcf3-ccdc6cdf2963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('village', 0.8886889219284058),\n",
              " ('neighborhood', 0.8183848261833191),\n",
              " ('park', 0.81337970495224),\n",
              " ('hotel', 0.8030052185058594),\n",
              " ('camp', 0.7653670907020569),\n",
              " ('california', 0.7601495981216431),\n",
              " ('house', 0.7571349143981934),\n",
              " ('london', 0.7536922693252563),\n",
              " ('city', 0.7502504587173462),\n",
              " ('factory', 0.7485291957855225)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#YOUR CODE\n",
        "model_ted.wv.most_similar('town') #distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv5QMF4gco_f"
      },
      "source": [
        "How similar are the words \"town\" and \"house\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d3DwXOLeco_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e4a3c0-6400-4a1a-d490-a856ea834076"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75713503"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#YOUR CODE\n",
        "model_ted.wv.similarity('town','house')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7I5G-KpqbfH"
      },
      "source": [
        "<h4>Exercise 4.1 (3 Points)</h4>\n",
        "Now that we have trained our own embedding, lets test some classical ideas: \n",
        "implement the following formula. Print out the 10 words, that are most similar to this formula: <br>\n",
        "$King-Man+Woman=???$\n",
        "There are two ways of computing similarity in word Embeddings:\n",
        " - https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
        " - https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar_cosmul.html\n",
        "You should try out both! In this case one of them is better, but both of them are valid methods for computing similarity in the word-space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "S0y_5MLlqiMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6461fb77-f0a3-4e2e-b9f7-d515463d0355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('president', 0.8277165293693542),\n",
              " ('james', 0.7726967930793762),\n",
              " ('martin', 0.7601994276046753),\n",
              " ('luther', 0.7472172975540161),\n",
              " ('nelson', 0.7427788376808167),\n",
              " ('french', 0.7414793372154236),\n",
              " ('named', 0.7342217564582825),\n",
              " ('john', 0.7316243648529053),\n",
              " ('minister', 0.730933427810669),\n",
              " ('mary', 0.7280852794647217)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#Your Implementation goes here!\n",
        "model_ted.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMlPdqqZco_i"
      },
      "source": [
        "<h4>Exercise 4.2 (2 Points)</h4>\n",
        "The expected outcome (Queen) should be one of the top ten most similar words. But there are also a lot of words, that you would not expect. Think about where how these words might be connected to the formula. Take your time and understand why some of the words (luther, mary, dr, president) might be in this list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snfyuAn3iraJ"
      },
      "source": [
        "YOUR ANSWER GOES HERE\n",
        "\n",
        "These words are in the list perhaps because they are found within the same vector space (similar to the  the words) used in the formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMtpPOVtaBup"
      },
      "source": [
        "#### t-SNE visualization\n",
        "\n",
        "We will use the t-SNE algorithm, given belwo, for visualization. The so-called t-Distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised and non-linear machine learning technique. It is commonly used for visualizing high dimensional data (just like our high dimensional vectors). You do not have to understand the code, it's purpose is simply to give you an idea of how the data is arranged in high dimensional space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej8Ud778co_k"
      },
      "source": [
        "<h4>Exercise 4.3 (2 Points)</h4>\n",
        "To use the t-SNE code below, first put a list of the top 100 words (as strings) into a variable `words_top_ted`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xvlyyjf6co_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e21a6e-99eb-48f3-d2cc-3196360d1d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'and', 'to', 'of', 'a', 'that', 'i', 'in', 'it', 'you', 'we', 'is', 's', 'this', 'so', 'they', 'was', 'for', 'are', 'have', 'but', 'what', 'on', 'with', 'one', 'can', 't', 'about', 'there', 'be', 'as', 'at', 'all', 'not', 'do', 'my', 're', 'people', 'like', 'if', 'from', 'now', 'our', 'he', 'an', 'just', 'these', 'or', 'when', 'because', 'very', 'me', 'out', 'by', 'them', 'how', 'know', 'up', 'going', 'had', 'more', 'think', 'who', 'were', 'see', 'two', 'your', 'their', 'which', 'would', 'here', 'really', 'get', 've', 'then', 'm', 'world', 'us', 'time', 'some', 'has', 'don', 'actually', 'into', 'hundred', 'way', 'where', 'will', 'years', 'things', 'other', 'no', 'could', 'go', 'well', 'want', 'been', 'make', 'right', 'she']\n"
          ]
        }
      ],
      "source": [
        "#Your implementation goes here!\n",
        "top_100_word=100\n",
        "words_top_ted=[word for(word,count) in counts_ted_top1000tupels][:top_100_word]#use list comprehension to get the top 100 words.\n",
        "print(words_top_ted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g8JIRw4co_n"
      },
      "source": [
        "The following code gets the corresponding vectors from the model, assuming it's called `model_ted`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0-lLF1lZaBus",
        "outputId": "decff1e9-4a0c-4308-ba0e-5836eee68328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-44957c02f90d>:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  words_top_vec_ted = model_ted[words_top_ted]\n"
          ]
        }
      ],
      "source": [
        "# This assumes words_top_ted is a list of strings, the top 250 words\n",
        "words_top_vec_ted = model_ted[words_top_ted]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SgjCkvCco_p"
      },
      "source": [
        "The next few lines are for the t-SNE visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HeJF5ut9aBux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50729e8f-b76b-4cbf-ba80-f875c108c50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE \n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "words_top_ted_tsne = tsne.fit_transform(words_top_vec_ted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "J2VgYLIZaBu2",
        "outputId": "4e986398-98d8-4565-a816-ac2d542fc2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"ee445cc9-74e8-4195-acca-76b46a7f749c\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"58fb68f0-404a-4821-a5aa-36287de26602\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"},{\"id\":\"1036\"}],\"left\":[{\"id\":\"1017\"}],\"renderers\":[{\"id\":\"1034\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1025\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1030\"},\"glyph\":{\"id\":\"1032\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1033\"},\"view\":{\"id\":\"1035\"}},\"id\":\"1034\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1030\"}},\"id\":\"1035\",\"type\":\"CDSView\"},{\"attributes\":{\"data\":{\"names\":[\"the\",\"and\",\"to\",\"of\",\"a\",\"that\",\"i\",\"in\",\"it\",\"you\",\"we\",\"is\",\"s\",\"this\",\"so\",\"they\",\"was\",\"for\",\"are\",\"have\",\"but\",\"what\",\"on\",\"with\",\"one\",\"can\",\"t\",\"about\",\"there\",\"be\",\"as\",\"at\",\"all\",\"not\",\"do\",\"my\",\"re\",\"people\",\"like\",\"if\",\"from\",\"now\",\"our\",\"he\",\"an\",\"just\",\"these\",\"or\",\"when\",\"because\",\"very\",\"me\",\"out\",\"by\",\"them\",\"how\",\"know\",\"up\",\"going\",\"had\",\"more\",\"think\",\"who\",\"were\",\"see\",\"two\",\"your\",\"their\",\"which\",\"would\",\"here\",\"really\",\"get\",\"ve\",\"then\",\"m\",\"world\",\"us\",\"time\",\"some\",\"has\",\"don\",\"actually\",\"into\",\"hundred\",\"way\",\"where\",\"will\",\"years\",\"things\",\"other\",\"no\",\"could\",\"go\",\"well\",\"want\",\"been\",\"make\",\"right\",\"she\"],\"x1\":{\"__ndarray__\":\"UW9gwi4DNcKZoBBBoCrMwrMIBkK6KRlBiDMsQ4NZx8IrktNBROsYQ99FNEN+oPRCEPrbQkNvRkFxMKzBupIpQzXzCUO9TKbCtlPfPw1p/0LnIvTBLbRWQnqKFcP7wivD7QAowjVZlsGCXGxBhrMBwxvNr8IGVfVCmTKyQYCMDsMcOWJCkcSYws0wh0L2bDhDRXuowfFovcHa8e3C/EblQOWrBsPFGSbCDL3rQkkiVkMGDNvCGDaGQEiDVcPFd+nC0ddCwR66IMHIt9PBYb8MwvL3PcNImCLDL5rNwbIrqUKhoYhCjr1Aw5NzwMKQgM3CxpdPQZ2wlELkm8FCjXySQYt1MELmgsbCNa00Q4NRDkO26ARCPXZwwpS7bMLKP+zAPR+aQkcJEEOISOzBUMUlQ9wpPsExRUbCPvBjQplQekKtXAHD7xEFQ1u0ZcE7NSLDBR2MwnV7j0GPAZDCOCk0woVnRMJFTMhBPtqJQmdrOUKPDSDCQ3RjQgQyUcLCFtlCJ9+TQvqyzUIw/ZPCca5WQw==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]},\"x2\":{\"__ndarray__\":\"OD0YwRszh0EeiJjCj5LAQShFdMEOn9BBNNzIP7nevMBZnDhC4TL+QexCGUJLzWfCHw+Twob+Ez+/02lCkJ1oQtuqqsKHhUpCa5CCw+a0x0LFZA5CQIq5Qj5eCkP1ztVAK+IOwniwKMPTMExDht25Qoyks0Lp5qjB+H8ZQ5o7rsJuYWdCyxjQwtkhksJncBDDaTmCw6QUzMKUq1tCuwgcwkOZ6UC7UYxCqq8ywwmbG8JCdj5DybdoQuL5CULI1hHCf46+wa85F0JXedFCsqQqQ0j3VcJbdlBCEpuLwrUov0I1/yHCTXbIQjPQkcLWehvDagL4wqQskcG2l4JBRT94w0iyYsJ+jv9CoBsnw0cxM8OLhoBBiU8zw9Zwq0LPOqVC7n3Uwn0+7kLMzIXAIaWHwqM9CEMGZ5TCjDoGQ0QP4kF8JCfDpNg4Q0PqX0EnxhTCsZANQ/D14EIfG3lBR9Acw0ZIXEOgEaJCDIw3Q9tGJcOToDjDbnvdwpcTPUJeRVJCMmVmw7n08sLC4fTBj/+OwQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[100]}},\"selected\":{\"id\":\"1046\"},\"selection_policy\":{\"id\":\"1045\"}},\"id\":\"1030\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1039\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1030\"},\"text\":{\"field\":\"names\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1036\",\"type\":\"LabelSet\"},{\"attributes\":{\"text\":\"word2vec T-SNE for most common words\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"AllLabels\"},{\"attributes\":{\"formatter\":{\"id\":\"1042\"},\"major_label_policy\":{\"id\":\"1044\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"}]},\"id\":\"1025\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"1039\"},\"major_label_policy\":{\"id\":\"1041\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1032\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1033\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n",
              "  var render_items = [{\"docid\":\"58fb68f0-404a-4821-a5aa-36287de26602\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"ee445cc9-74e8-4195-acca-76b46a7f749c\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        }
      ],
      "source": [
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"word2vec T-SNE for most common words\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
        "                                    x2=words_top_ted_tsne[:,1],\n",
        "                                    names=words_top_ted))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
        "\n",
        "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "a65b432e5f6ef459234b115bd38a5a83e07ef48382088862c801d0ac79c3a091"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}