{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxlEMy3qppiyMD+wfkK5pu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeNsiah10/DLTFpT/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 574,
      "metadata": {
        "id": "OIzSLZh6uOrR"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits=load_digits()"
      ],
      "metadata": {
        "id": "GRqOMaanuUrj"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = digits.images  # 8x8 images\n",
        "targets = digits.target"
      ],
      "metadata": {
        "id": "1CgXR3Qyubij"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you've already loaded the digits dataset into X and y\n",
        "# X: Input features (8x8 greyscale images)\n",
        "# y: Target labels (0-9)\n",
        "\n",
        "# Plot the first ten images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(inputs[i].reshape(8, 8), cmap='gray')  # Reshape to 8x8 and use grayscale colormap\n",
        "    ax.axis('off')  # Hide axes\n",
        "    ax.set_title(f\"Label: {targets[i]}\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "xM7ek8iw2G9l",
        "outputId": "a91b08f1-9c27-465f-a3dd-198bf4fdc29e"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Reshape the images into vectors of shape (64)\n",
        "inputs = inputs.reshape(-1,64)\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ISuCGMwUx2Qr",
        "outputId": "1f2c5efb-fb17-4946-fd32-84197a0b1242"
      },
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalisi the inputs\n",
        "inputs = inputs / 16.0\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ih5rPkMhySSM",
        "outputId": "76728451-d70e-40a5-897f-68b6ea7697f2"
      },
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
            " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
            " ...\n",
            " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
            " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
            " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = 10\n",
        "def encode(target, num_classes):\n",
        "   return np.eye(num_classes)[target.astype(int)]\n",
        "targets = encode(targets, num_classes)\n",
        "#targets = np.eye(num_classes)[targets.astype(int)]\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TwtWx1H1yh8G",
        "outputId": "d035b88a-cfde-4950-fcf8-871564fc4da2"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_minibatches(inputs, targets, batch_size):\n",
        "    indices = np.random.permutation(len(inputs))\n",
        "    for i in range(0, len(inputs), batch_size):\n",
        "        batch_indices = indices[i:i + batch_size]\n",
        "        yield inputs[batch_indices], targets[batch_indices]\n"
      ],
      "metadata": {
        "id": "dnVmQQtF0dSh"
      },
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __call__(self, inputs):\n",
        "        # Apply the sigmoid activation function\n",
        "         return 1 / (1 + np.exp(-inputs))\n",
        "\n"
      ],
      "metadata": {
        "id": "YhalpIvJ0tha"
      },
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __call__(self, inputs):\n",
        "        # Calculate the softmax along the second axis (axis=1)\n",
        "        exp_input = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        softmax_output = exp_input / np.sum(exp_input, axis=1, keepdims=True)\n",
        "        return softmax_output\n"
      ],
      "metadata": {
        "id": "nGBjlfoo5vkC"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPLayer:\n",
        "    def __init__(self, input_size, num_units, activation):\n",
        "        self.input_size=input_size\n",
        "        self.num_units=num_units\n",
        "        self.Weight = np.random.normal(0., 0.2, (input_size, num_units))\n",
        "        self.bias = np.zeros((1, num_units))\n",
        "        self.activation_func = activation()\n",
        "     #function to forward pass the inputs\n",
        "    def forward(self, inputs):\n",
        "        z = np.dot(inputs, self.Weight) + self.bias\n",
        "        return self.activation(z)\n"
      ],
      "metadata": {
        "id": "dfO_9NXn6uW-"
      },
      "execution_count": 584,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, layer_sizes):\n",
        "        self.layers = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            if i == len(layer_sizes) - 2:  # last layer\n",
        "                self.layers.append(MLPLayer(layer_sizes[i], layer_sizes[i+1], Softmax))\n",
        "                #any layer other than the last layer\n",
        "            else:\n",
        "                self.layers.append(MLPLayer(layer_sizes[i], layer_sizes[i+1], Sigmoid))\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        for layer in self.layers:\n",
        "            input_data = layer.forward(input_data)\n",
        "        return input_data\n"
      ],
      "metadata": {
        "id": "OvtSxOD47qGy"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CCE_Loss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        n = y_true.shape[0]\n",
        "        log_likelihood = -np.log(y_pred[range(n), y_true])\n",
        "        loss = np.sum(log_likelihood) / n\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "l5lYzkW3-Msd"
      },
      "execution_count": 586,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical Cross Entropy loss Backwards\n",
        "class CCE:\n",
        "    def __call__(self, y_pred, targets):\n",
        "        return -np.sum(targets * np.log(y_pred))\n",
        "    #backward the loss using the derivative of the loss function\n",
        "    def backward(self, y_pred, targets):\n",
        "        return y_pred - targets\n"
      ],
      "metadata": {
        "id": "Twtf_q0ix3lk"
      },
      "execution_count": 587,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid Backwards\n",
        "class Sigmoid:\n",
        "    def __call__(self, inputs):\n",
        "        return 1 / (1 + np.exp(-inputs))\n",
        "\n",
        "    def backward(self, inputs):\n",
        "       sigmoid=self.__call__(inputs)\n",
        "       return sigmoid-(1-sigmoid)"
      ],
      "metadata": {
        "id": "2u0Fbly1yvY9"
      },
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MLP Layer Weights Backwards\n",
        "class MLPLayer:\n",
        "    def __init__(self, input_size, num_units, activation):\n",
        "        self.weights = np.random.normal(0, 0.2, (num_units, input_size))\n",
        "        self.bias = np.zeros((num_units, 1))\n",
        "        self.activation = activation()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs # Save input for backward pass\n",
        "        self.z = np.dot(self.weights, inputs) + self.bias\n",
        "        return self.activation(self.z)\n",
        "\n",
        "    def backward(self, error, learning_rate):\n",
        "         dL_dz = error * self.activation.backward(self.z)\n",
        "         dL_dw = np.dot(self.inputs.T, dL_dz)/len(self.inputs) # Fix the shape here\n",
        "         dL_dx = np.dot(dL_dz, self.weights.T)\n",
        "         self.weights -= learning_rate * dL_dw\n",
        "         self.bias -= learning_rate * np.sum(dL_dz, axis=0, keepdims=True)\n",
        "         return dL_dx\n",
        "\n",
        "# MLP Backward\n",
        "class MLP:\n",
        "    def __init__(self, layer_sizes):\n",
        "        self.layers = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            if i == len(layer_sizes) - 2:\n",
        "                self.layers.append(MLPLayer(layer_sizes[i], layer_sizes[i+1], Softmax))\n",
        "            else:\n",
        "                self.layers.append(MLPLayer(layer_sizes[i], layer_sizes[i+1], Sigmoid))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(inputs)\n",
        "        return x\n",
        "\n",
        "    def backward(self, error, learning_rate):\n",
        "        for layer in reversed(self.layers):\n",
        "            error = layer.backward(error, learning_rate)\n",
        "\n",
        "def get_minibatches(inputs, targets, batch_size):\n",
        "    indices = np.random.permutation(len(inputs))\n",
        "    for i in range(0, len(inputs), batch_size):\n",
        "        batch_indices = indices[i:i + batch_size]\n",
        "        yield inputs[batch_indices], targets[batch_indices]\n",
        "\n",
        "class CCE_Loss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        n = y_true.shape[0]\n",
        "        log_likelihood = -np.log(y_pred[range(n), np.argmax(y_true, axis=1)])\n",
        "        loss = np.sum(log_likelihood) / n\n",
        "        return loss\n",
        "\n",
        "class CCE:\n",
        "    def __call__(self, y_pred, targets):\n",
        "        return -np.sum(targets * np.log(y_pred))\n",
        "\n",
        "    def backward(self, y_pred, targets):\n",
        "        return y_pred - targets"
      ],
      "metadata": {
        "id": "HDfyX7EE1Dl-"
      },
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp(mlp, inputs, targets, num_epochs=100, learning_rate=0.01, batch_size=32):\n",
        "    loss_function = CCE()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Generate mini-batches\n",
        "        for minibatch_inputs, minibatch_targets in get_minibatches(inputs, targets, batch_size):\n",
        "            # Forward pass\n",
        "            predictions = mlp.forward(minibatch_inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_function(predictions, minibatch_targets)\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backward pass\n",
        "            error = loss_function.backward(predictions, minibatch_targets)\n",
        "            mlp.backward(error, learning_rate)\n",
        "\n",
        "        # Print average loss for the epoch\n",
        "        average_loss = total_loss / len(inputs)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}\")\n",
        "print(\"Inputs shape:\", inputs.shape)\n",
        "print(\"Targets shape:\", targets.shape)\n"
      ],
      "metadata": {
        "id": "dmA3j5nBCUSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "13c78bc8-88f1-4cd7-a88e-49b4a53c7eda"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs shape: (1797, 64)\n",
            "Targets shape: (1797, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dTHpkjBYa2fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model\n",
        "layer_sizes = [64, 128, 10]  # Input size, hidden layer size, output size\n",
        "mlp_model = MLP(layer_sizes)\n",
        "train_mlp(mlp_model, inputs, targets, num_epochs=100, learning_rate=0.01, batch_size=32)\n"
      ],
      "metadata": {
        "id": "ASGHH5ioL2rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrnB6xogUGeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}